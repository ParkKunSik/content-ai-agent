# [Profile Configuration]
# local, dev, prod
ENV="local"

# [LLM Provider Configuration]
# VERTEX_AI | OPENAI
LLM_PROVIDER="VERTEX_AI"

# [GCP/Vertex AI Configuration]
GCP_PROJECT_ID="your-gcp-project-id"
GCP_REGION="asia-northeast3"
# Local Dev Only: Path to credentials if not using 'gcloud auth application-default login'
# GOOGLE_APPLICATION_CREDENTIALS="path/to/key.json"
# Available models (2026-01-20):
# - gemini-2.5-pro (current, stable, advanced reasoning)
# - gemini-2.5-flash (current, stable, fast processing)
# (Gemini 2.5 Pro/Flash Max token size: 65,535 tokens)
# - gemini-3-pro-preview (latest, preview, cutting-edge reasoning)
# - gemini-3-flash-preview (latest, preview, fast processing)
# (Gemini 3 Pro/Flash-preview Max token size: 32,768 tokens)
# - nano-banana-pro (experimental, high-performance)
VERTEX_AI_MODEL_PRO="gemini-2.5-pro"
VERTEX_AI_MODEL_FLASH="gemini-2.5-flash"

# [OpenAI Configuration]
# Required if LLM_PROVIDER="OPENAI"
# OPENAI_API_KEY="sk-xxxxx"
# OPENAI_ORG_ID="org-xxxxx"
#
# Available models (2026-02 기준):
# [temperature 지원 모델]
# - gpt-4o (flagship, multimodal, 128k context, $2.50/$10.00 per 1M tokens)
# - gpt-4o-mini (cost-efficient, 128k context, $0.15/$0.60 per 1M tokens)
# - gpt-4.1 (large context, 1M context, $2.00/$8.00 per 1M tokens)
# - gpt-4.1-mini / gpt-4.1-nano (1M context, cost-efficient)
#
# [temperature 미지원 모델 (Reasoning)]
# - gpt-5 / gpt-5-mini / gpt-5-nano (400k context, reasoning 내장)
# - o1 / o1-mini / o1-preview (초기 reasoning)
# - o3 / o3-mini / o3-pro (고급 reasoning)
# - o4-mini (fast reasoning, math/coding 최적화)
# [주의] temperature, top_p 등 샘플링 파라미터 사용 불가
#
# [Recommended] PRO: gpt-4o 또는 gpt-4.1, FLASH: gpt-4o-mini
OPENAI_MODEL_PRO="gpt-4o"
OPENAI_MODEL_FLASH="gpt-4o-mini"

# [Internal Identity]
INTERNAL_AGENT_ID="local-content-ai-agent-v1"

# [Elasticsearch Configuration]
# ES_REFERENCE: Existing Wadiz data retrieval / ES_MAIN: Analysis result storage
ES_REFERENCE_HOST="localhost"
ES_REFERENCE_PORT=9200
ES_REFERENCE_USERNAME=""
ES_REFERENCE_PASSWORD=""
ES_REFERENCE_USE_SSL=false
ES_REFERENCE_VERIFY_CERTS=false
ES_REFERENCE_TIMEOUT=30

ES_MAIN_HOST="localhost"
ES_MAIN_PORT=9200
ES_MAIN_USERNAME=""
ES_MAIN_PASSWORD=""
ES_MAIN_USE_SSL=false
ES_MAIN_VERIFY_CERTS=false
ES_MAIN_TIMEOUT=30

# ES 인덱스/Alias 설정 (기존 - 하위 호환)
ANALYSIS_RESULT_INDEX=core-content-analysis-result
ANALYSIS_RESULT_ALIAS=core-content-analysis-result-alias

# ES 인덱스/Alias 설정 (Provider별)
ANALYSIS_RESULT_VERTEX_AI_INDEX=core-content-analysis-result-vertex-ai
ANALYSIS_RESULT_VERTEX_AI_ALIAS=core-content-analysis-result-vertex-ai-alias
ANALYSIS_RESULT_OPENAI_INDEX=core-content-analysis-result-openai
ANALYSIS_RESULT_OPENAI_ALIAS=core-content-analysis-result-openai-alias

# Provider 무관하게 기본 인덱스 사용 (true: 기본 인덱스, false: Provider별 인덱스)
USE_DEFAULT_ES_INDEX=True
