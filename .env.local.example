# [Profile Configuration]
# local, dev, prod
ENV="local"

# [LLM Provider Configuration]
# VERTEX_AI | OPENAI
LLM_PROVIDER="VERTEX_AI"

# [GCP/Vertex AI Configuration]
GCP_PROJECT_ID="your-gcp-project-id"
GCP_REGION="asia-northeast3"
# Local Dev Only: Path to credentials if not using 'gcloud auth application-default login'
# GOOGLE_APPLICATION_CREDENTIALS="path/to/key.json"
# Available models (2026-01-20):
# - gemini-2.5-pro (current, stable, advanced reasoning)
# - gemini-2.5-flash (current, stable, fast processing)
# (Gemini 2.5 Pro/Flash Max token size: 65,535 tokens)
# - gemini-3-pro-preview (latest, preview, cutting-edge reasoning)
# - gemini-3-flash-preview (latest, preview, fast processing)
# (Gemini 3 Pro/Flash-preview Max token size: 32,768 tokens)
# - nano-banana-pro (experimental, high-performance)
VERTEX_AI_MODEL_PRO="gemini-2.5-pro"
VERTEX_AI_MODEL_FLASH="gemini-2.5-flash"

# [OpenAI Configuration]
# Required if LLM_PROVIDER="OPENAI"
# OPENAI_API_KEY="sk-xxxxx"
# OPENAI_ORG_ID="org-xxxxx"
# Available models (2026-02-12):
# - gpt-4o (flagship, multimodal, 128k context, 16k output, $2.50/$10.00 per 1M tokens)
# - gpt-4o-mini (cost-efficient, 128k context, 16k output, $0.15/$0.60 per 1M tokens)
# - gpt-4.1 (large context, 1M context, 32k output, $2.00/1M input, $8.00/1M output)
# - o1 (reasoning, 200k context, 100k output, complex tasks)
# - o3 (advanced reasoning, 200k context, 100k output)
# - o4-mini (fast reasoning, cost-efficient, math/coding optimized)
# [Note] o-series models: reasoning tokens are billed as output (actual cost may exceed visible output)
# [Recommended] PRO: gpt-4o or o3 (complex), FLASH: gpt-4o-mini (simple/fast)
OPENAI_MODEL_PRO="gpt-4o"
OPENAI_MODEL_FLASH="gpt-4o-mini"

# [Internal Identity]
INTERNAL_AGENT_ID="local-content-ai-agent-v1"

# [System Instruction]
# Version of the system prompt templates to use (folder name in src/prompts/templates/system/)
SYSTEM_INSTRUCTION_VERSION="v1"

# [Elasticsearch Configuration]
# ES_REFERENCE: Existing Wadiz data retrieval / ES_MAIN: Analysis result storage
ES_REFERENCE_HOST="localhost"
ES_REFERENCE_PORT=9200
ES_REFERENCE_USERNAME=""
ES_REFERENCE_PASSWORD=""
ES_REFERENCE_USE_SSL=false
ES_REFERENCE_VERIFY_CERTS=false
ES_REFERENCE_TIMEOUT=30

ES_MAIN_HOST="localhost"
ES_MAIN_PORT=9200
ES_MAIN_USERNAME=""
ES_MAIN_PASSWORD=""
ES_MAIN_USE_SSL=false
ES_MAIN_VERIFY_CERTS=false
ES_MAIN_TIMEOUT=30

# ES 인덱스/Alias 설정
ANALYSIS_RESULT_INDEX=core-content-analysis-result
ANALYSIS_RESULT_ALIAS=core-content-analysis-result-alias
